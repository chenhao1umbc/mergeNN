{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This file contains all the templates \n",
    "Each cell contains one template will executable code. Everytime train or merge the neural network, just pick one of the templates and change the running id. In this way, the repo will be expanded too fast with many similar files\n",
    "\n",
    "### Instructions\n",
    "1. pick one of cells in the `training section` and copy all the content\n",
    "2. past the content in a new python file, e.g. `n1.py`. and change the id to id1\n",
    "3. past the content in another new python file, e.g. `n2.py` and change the id to id2\n",
    "\n",
    "4. pick one of cells in the `merging section` and copy all the content \n",
    "5. past the content in a new python file and run with the previous two ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell is train_cifar0.py\n",
    "This file is using CIFAR100, \n",
    "Resnet18 or shufflenet, which can be changed in the load model section\n",
    "\"\"\"\n",
    "#%% load dependency\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.io import imread\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "\n",
    "#%% prepare data\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR100(root='./data', train=True, transform=transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomCrop(32, 4),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]), download=True),\n",
    "    batch_size=128, shuffle=True,\n",
    "    num_workers=4, pin_memory=True)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    datasets.CIFAR100(root='./data', train=False, transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=128, shuffle=False,\n",
    "    num_workers=4, pin_memory=True)\n",
    "\n",
    "#%% load model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False) # original \n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
    "# model.conv1 = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model = model.cuda()\n",
    "\n",
    "#%% train_net\n",
    "id = 'CIFAR0' # for diff. runs\n",
    "best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "opt = {'epochs':200}\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100, 150], gamma=0.1)\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(opt['epochs']):\n",
    "    model.train()\n",
    "\n",
    "    # print training info\n",
    "    print(\"### Epoch {}:\".format(epoch))\n",
    "    total_train_examples = 0\n",
    "    num_correct_train = 0\n",
    "\n",
    "    for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        gt_label = gt_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_func(predictions, gt_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted_class = predictions.max(1)\n",
    "        total_train_examples += predicted_class.size(0)\n",
    "        num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "    # get results\n",
    "    train_acc = num_correct_train / total_train_examples\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # evaluation\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # don't save parameter gradients/changes since this is not for model training\n",
    "        for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation results\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # Finally, save model if the validation accuracy is the best so far\n",
    "    if val_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_acc\n",
    "        print(\"Validation accuracy improved; saving model.\")\n",
    "        torch.save(model.state_dict(), f'teachers/teacher{id}.pt')\n",
    "    scheduler.step()\n",
    "\n",
    "#%% plot train and val results\n",
    "epochs_list = list(range(opt['epochs']))\n",
    "plt.figure()\n",
    "plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('prediction accuracy')\n",
    "plt.ylim(0.01, 1)\n",
    "plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "plt.legend()\n",
    "plt.savefig(f'train_val{id}.png')\n",
    "plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell is train Lung Cancer Data (LCD) 2d with individual sample\n",
    "This file is using LCD and treat each slice as an independ data sample \n",
    "Resnet18 or shufflenet, which can be changed in the load model section\n",
    "\"\"\"\n",
    "#%% load dependency\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.io import imread\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "\n",
    "#%% prepare data\n",
    "neg, pos = torch.load('./data/LCD/neg_pos.pt') # check prep_data.py for more info\n",
    "neg_all, pos_all = neg.reshape(-1,1,64,64), pos.reshape(-1,1,64,64)\n",
    "if True:  # if False means split by objects\n",
    "    idx = torch.randperm(pos_all.shape[0])\n",
    "    neg_all = neg_all[idx]\n",
    "    pos_all = pos_all[idx]  #36992, 64, 64]\n",
    "num_train = 29600\n",
    "num_val = 3696\n",
    "num_test = 3696\n",
    "split1 = num_val+num_train\n",
    "split2 = num_val+num_train + num_test\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.cat((pos_all[:num_train], neg_all[:num_train]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_train, dtype=int), torch.zeros(num_train,  dtype=int)), dim=0))\n",
    "val_dataset = Data.TensorDataset(torch.cat((pos_all[num_train:split1],neg_all[num_train:split1]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_val, dtype=int), torch.zeros(num_val, dtype=int)), dim=0))\n",
    "test_dataset = Data.TensorDataset(torch.cat((pos_all[split1:split2], neg_all[split1:split2]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_test, dtype=int), torch.zeros(num_test, dtype=int)), dim=0))\n",
    "train_batchsize = 128\n",
    "eval_batchsize = 64\n",
    "train_loader = DataLoader(train_dataset, train_batchsize, shuffle=True)                                      \n",
    "validation_loader = DataLoader(val_dataset, eval_batchsize)\n",
    "test_loader = DataLoader(test_dataset, eval_batchsize)\n",
    "\n",
    "#%% load model\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "# model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 24, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "model = model.cuda()\n",
    "\n",
    "#%% train_net\n",
    "id = 'LCD0' # for diff. runs\n",
    "best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "opt = {'epochs':100}\n",
    "optimizer = torch.optim.RAdam(model.parameters(),\n",
    "                lr= 0.001,\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(opt['epochs']):\n",
    "    model.train()\n",
    "\n",
    "    # print training info\n",
    "    print(\"### Epoch {}:\".format(epoch))\n",
    "    total_train_examples = 0\n",
    "    num_correct_train = 0\n",
    "\n",
    "    # for batch_index, (inputs, gt_label) in tqdm(enumerate(train_loader), total=len(train_dataset)//train_batchsize):\n",
    "    for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        gt_label = gt_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_func(predictions, gt_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted_class = predictions.max(1)\n",
    "        total_train_examples += predicted_class.size(0)\n",
    "        num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "    # get results\n",
    "    train_acc = num_correct_train / total_train_examples\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # evaluation\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # don't save parameter gradients/changes since this is not for model training\n",
    "        for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation results\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # Finally, save model if the validation accuracy is the best so far\n",
    "    if val_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_acc\n",
    "        print(\"Validation accuracy improved; saving model.\")\n",
    "        torch.save(model.state_dict(), f'teachers/teacher{id}.pt')\n",
    "\n",
    "\n",
    "#%% plot train and val results\n",
    "epochs_list = list(range(opt['epochs']))\n",
    "plt.figure()\n",
    "plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('prediction accuracy')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "plt.legend()\n",
    "plt.savefig(f'train_val{id}.png')\n",
    "plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell is train Duke Breast Cancer (DBC) 2d with individual sample\n",
    "This file is using DBC and treat each slice as an independ data sample \n",
    "Resnet18 or shufflenet, which can be changed in the load model section\n",
    "\"\"\"\n",
    "#%% load dependency\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.io import imread\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "\n",
    "#%% prepare data\n",
    "neg_all = torch.load('./data/DBC/neg_all.pt') # check prep_data.py for more info\n",
    "pos_all = torch.load('./data/DBC/pos_all.pt')\n",
    "if True:  # if False means split by objects\n",
    "    idx = torch.randperm(pos_all.shape[0])\n",
    "    neg_all = neg_all[idx]\n",
    "    pos_all = pos_all[idx]\n",
    "num_train = 2600+2200\n",
    "num_val = 2200//2\n",
    "num_test = 2200//2\n",
    "split1 = num_val+num_train\n",
    "split2 = num_val+num_train + num_test\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.cat((pos_all[:num_train], neg_all[:num_train]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_train, dtype=int), torch.zeros(num_train,  dtype=int)), dim=0))\n",
    "val_dataset = Data.TensorDataset(torch.cat((pos_all[num_train:split1],neg_all[num_train:split1]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_val, dtype=int), torch.zeros(num_val, dtype=int)), dim=0))\n",
    "test_dataset = Data.TensorDataset(torch.cat((pos_all[split1:split2], neg_all[split1:split2]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_test, dtype=int), torch.zeros(num_test, dtype=int)), dim=0))\n",
    "train_batchsize = 64\n",
    "eval_batchsize = 32\n",
    "train_loader = DataLoader(train_dataset, train_batchsize, shuffle=True)                                      \n",
    "validation_loader = DataLoader(val_dataset, eval_batchsize)\n",
    "test_loader = DataLoader(test_dataset, eval_batchsize)\n",
    "\n",
    "#%% load model\n",
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# model = torch.hub.load('pytorch/vision:v0.10.0', 'shufflenet_v2_x1_0', pretrained=True)\n",
    "# model.conv1 = nn.Conv2d(1, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
    "model = model.cuda()\n",
    "\n",
    "#%% train_net\n",
    "id = 'DBC0' # for diff. runs\n",
    "best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "opt = {'epochs':100}\n",
    "optimizer = torch.optim.RAdam(model.parameters(),\n",
    "                lr= 0.001,\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(opt['epochs']):\n",
    "    model.train()\n",
    "\n",
    "    # print training info\n",
    "    print(\"### Epoch {}:\".format(epoch))\n",
    "    total_train_examples = 0\n",
    "    num_correct_train = 0\n",
    "\n",
    "    # for batch_index, (inputs, gt_label) in tqdm(enumerate(train_loader), total=len(train_dataset)//train_batchsize):\n",
    "    for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        gt_label = gt_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_func(predictions, gt_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted_class = predictions.max(1)\n",
    "        total_train_examples += predicted_class.size(0)\n",
    "        num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "    # get results\n",
    "    train_acc = num_correct_train / total_train_examples\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # evaluation\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # don't save parameter gradients/changes since this is not for model training\n",
    "        for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation results\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # Finally, save model if the validation accuracy is the best so far\n",
    "    if val_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_acc\n",
    "        print(\"Validation accuracy improved; saving model.\")\n",
    "        torch.save(model.state_dict(), f'teachers/teacher{id}.pt')\n",
    "\n",
    "\n",
    "#%% plot train and val results\n",
    "epochs_list = list(range(opt['epochs']))\n",
    "plt.figure()\n",
    "plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('prediction accuracy')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "plt.legend()\n",
    "plt.savefig(f'train_val{id}.png')\n",
    "plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell is train LCD 3d\n",
    "This file is using LCD and treat each slice as an independ data sample \n",
    "Using a ResNet18-3D\n",
    "\"\"\"\n",
    "#%% load dependency\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.io import imread\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "\n",
    "#%% prepare data\n",
    "neg, pos = torch.load('./data/LCD/neg_pos.pt') # neg and pos each has [1156,32,64,64]\n",
    "# neg = torch.cat((neg[:,:8],neg[:,8:16],neg[:,16:24], neg[:,24:]), dim=0)\n",
    "# pos = torch.cat((pos[:,:8],pos[:,8:16],pos[:,16:24], pos[:,24:]), dim=0) # shape [1156*4, 8, 64, 64]\n",
    "if True:  # if False means split by objects\n",
    "    idx = torch.randperm(pos.shape[0])\n",
    "    neg_all = neg[idx][:,None]\n",
    "    pos_all = pos[idx][:,None]\n",
    "num_train = 900\n",
    "num_val = 156\n",
    "num_test = 100\n",
    "split1 = num_val+num_train\n",
    "split2 = num_val+num_train + num_test\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.cat((pos_all[:num_train], neg_all[:num_train]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_train, dtype=int), torch.zeros(num_train,  dtype=int)), dim=0))\n",
    "val_dataset = Data.TensorDataset(torch.cat((pos_all[num_train:split1],neg_all[num_train:split1]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_val, dtype=int), torch.zeros(num_val, dtype=int)), dim=0))\n",
    "test_dataset = Data.TensorDataset(torch.cat((pos_all[split1:split2], neg_all[split1:split2]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_test, dtype=int), torch.zeros(num_test, dtype=int)), dim=0))\n",
    "train_batchsize = 128\n",
    "eval_batchsize = 64\n",
    "train_loader = DataLoader(train_dataset, train_batchsize, shuffle=True)                                      \n",
    "validation_loader = DataLoader(val_dataset, eval_batchsize)\n",
    "test_loader = DataLoader(test_dataset, eval_batchsize)\n",
    "\n",
    "#%% train_net\n",
    "from modules import *\n",
    "model = Resnet3D().cuda()\n",
    "\n",
    "id = 'res3d1' # for diff. runs\n",
    "fig_loc = './data/results/figures/'\n",
    "mod_loc = './data/results/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{id}/')): \n",
    "    print('made a new folder')\n",
    "    os.makedirs(fig_loc + f'{id}/')\n",
    "    os.makedirs(mod_loc + f'{id}/')\n",
    "fig_loc = fig_loc + f'{id}/'\n",
    "mod_loc = mod_loc + f'{id}/'\n",
    "\n",
    "best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "opt = {'epochs':100}\n",
    "optimizer = torch.optim.RAdam(model.parameters(),\n",
    "                lr= 0.001,\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(opt['epochs']):\n",
    "    model.train()\n",
    "\n",
    "    # print training info\n",
    "    print(\"### Epoch {}:\".format(epoch))\n",
    "    total_train_examples = 0\n",
    "    num_correct_train = 0\n",
    "\n",
    "    # for batch_index, (inputs, gt_label) in tqdm(enumerate(train_loader), total=len(train_dataset)//train_batchsize):\n",
    "    for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        gt_label = gt_label.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(inputs)\n",
    "        loss = loss_func(predictions, gt_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, predicted_class = predictions.max(1)\n",
    "        total_train_examples += predicted_class.size(0)\n",
    "        num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "    # get results\n",
    "    train_acc = num_correct_train / total_train_examples\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # evaluation\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): # don't save parameter gradients/changes since this is not for model training\n",
    "        for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation results\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # Finally, save model if the validation accuracy is the best so far\n",
    "    if val_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_acc\n",
    "        print(\"Validation accuracy improved; saving model.\")\n",
    "        torch.save(model.state_dict(), mod_loc+f'model_{id}.pt')\n",
    "\n",
    "        epochs_list = list(range(epoch+1))\n",
    "        plt.figure()\n",
    "        plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "        plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('prediction accuracy')\n",
    "        plt.ylim(0.5, 1)\n",
    "        plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "        plt.legend()\n",
    "        plt.savefig(fig_loc+f'train_val{id}_{epoch}.png')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "#%% plot train and val results\n",
    "epochs_list = list(range(opt['epochs']))\n",
    "plt.figure()\n",
    "plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('prediction accuracy')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "plt.legend()\n",
    "plt.savefig(fig_loc+f'train_val{id}.png')\n",
    "plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This cell is train LCD 3d with costomized modified ResNet3D \n",
    "This file is using LCD and treat each slice as an independ data sample \n",
    "\"\"\"\n",
    "#%% load dependency\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.io import imread\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "\n",
    "\n",
    "#%% load the model\n",
    "from modules import *\n",
    "class Resnet3D_m(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        #(maxpool): Cifar does not have it.\n",
    "        self.layer1 = nn.Sequential(\n",
    "            BasicBlock3D(16, 16),\n",
    "            BasicBlock3D(16, 16),\n",
    "            )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            BasicBlock3D(16, 16, stride=2, downsample=Downsample3D(16, 16)),\n",
    "            BasicBlock3D(16, 16),\n",
    "            )\n",
    "        self.layer3 = nn.Sequential(\n",
    "            BasicBlock3D(16, 32, stride=2, downsample=Downsample3D(16, 32)),\n",
    "            BasicBlock3D(32, 32),\n",
    "            )\n",
    "        self.avgpool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "#%% prepare data\n",
    "neg, pos = torch.load('./data/LCD/neg_pos.pt') # neg and pos each has [1156,32,64,64]\n",
    "\n",
    "for iseed in range(1,5):\n",
    "    torch.manual_seed(iseed)\n",
    "    if True:  # if False means split by objects\n",
    "        idx = torch.randperm(pos.shape[0])\n",
    "        neg_all = neg[idx][:,None]\n",
    "        pos_all = pos[idx][:,None]\n",
    "    num_train = 900\n",
    "    num_val = 128\n",
    "    num_test = 128\n",
    "    split1 = num_val+num_train\n",
    "    split2 = num_val+num_train + num_test\n",
    "\n",
    "    train_dataset = Data.TensorDataset(torch.cat((pos_all[:num_train], neg_all[:num_train]), dim=0), \\\n",
    "                    torch.cat((torch.ones(num_train, dtype=int), torch.zeros(num_train,  dtype=int)), dim=0))\n",
    "    val_dataset = Data.TensorDataset(torch.cat((pos_all[num_train:split1],neg_all[num_train:split1]), dim=0), \\\n",
    "                    torch.cat((torch.ones(num_val, dtype=int), torch.zeros(num_val, dtype=int)), dim=0))\n",
    "    test_dataset = Data.TensorDataset(torch.cat((pos_all[split1:split2], neg_all[split1:split2]), dim=0), \\\n",
    "                    torch.cat((torch.ones(num_test, dtype=int), torch.zeros(num_test, dtype=int)), dim=0))\n",
    "    train_batchsize = 64\n",
    "    eval_batchsize = 64\n",
    "    train_loader = DataLoader(train_dataset, train_batchsize, shuffle=True)                                      \n",
    "    validation_loader = DataLoader(val_dataset, eval_batchsize)\n",
    "    test_loader = DataLoader(test_dataset, eval_batchsize)\n",
    "\n",
    "    #%% train_net\n",
    "    model = Resnet3D_m().cuda()\n",
    "    id = f'res3d_m{iseed}' # for diff. runs\n",
    "    fig_loc = './data/results/figures/'\n",
    "    mod_loc = './data/results/models/'\n",
    "    if not(os.path.isdir(fig_loc + f'/{id}/')): \n",
    "        print('made a new folder')\n",
    "        os.makedirs(fig_loc + f'{id}/')\n",
    "        os.makedirs(mod_loc + f'{id}/')\n",
    "    fig_loc = fig_loc + f'{id}/'\n",
    "    mod_loc = mod_loc + f'{id}/'\n",
    "\n",
    "    best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "\n",
    "    opt = {'epochs':150}\n",
    "    optimizer = torch.optim.RAdam(model.parameters(),\n",
    "                    lr= 0.001,\n",
    "                    betas=(0.9, 0.999), \n",
    "                    eps=1e-8,\n",
    "                    weight_decay=0)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(opt['epochs']):\n",
    "        model.train()\n",
    "\n",
    "        # print training info\n",
    "        print(\"### Epoch {}:\".format(epoch))\n",
    "        total_train_examples = 0\n",
    "        num_correct_train = 0\n",
    "\n",
    "        # for batch_index, (inputs, gt_label) in tqdm(enumerate(train_loader), total=len(train_dataset)//train_batchsize):\n",
    "        for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(inputs)\n",
    "            loss = loss_func(predictions, gt_label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_train_examples += predicted_class.size(0)\n",
    "            num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get results\n",
    "        train_acc = num_correct_train / total_train_examples\n",
    "        print(\"Training accuracy: {}\".format(train_acc))\n",
    "        train_accs.append(train_acc)\n",
    "\n",
    "        # evaluation\n",
    "        total_val_examples = 0\n",
    "        num_correct_val = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad(): # don't save parameter gradients/changes since this is not for model training\n",
    "            for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "                inputs = inputs.cuda()\n",
    "                gt_label = gt_label.cuda()\n",
    "                predictions = model(inputs)\n",
    "\n",
    "                _, predicted_class = predictions.max(1)\n",
    "                total_val_examples += predicted_class.size(0)\n",
    "                num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "            # get validation results\n",
    "            val_acc = num_correct_val / total_val_examples\n",
    "            print(\"Validation accuracy: {}\".format(val_acc))\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        # Finally, save model if the validation accuracy is the best so far\n",
    "        if val_acc > best_validation_accuracy:\n",
    "            best_validation_accuracy = val_acc\n",
    "            print(\"Validation accuracy improved; saving model.\")\n",
    "            torch.save(model.state_dict(), mod_loc+f'model_{id}.pt')\n",
    "\n",
    "            epochs_list = list(range(epoch+1))\n",
    "            plt.figure()\n",
    "            plt.plot(epochs_list, train_accs, '-o', label='training set accuracy')\n",
    "            plt.plot(epochs_list, val_accs, '--x', label='validation set accuracy')\n",
    "            plt.xlabel('epoch')\n",
    "            plt.ylabel('prediction accuracy')\n",
    "            plt.ylim(0.5, 1)\n",
    "            plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "            plt.legend()\n",
    "            plt.savefig(fig_loc+f'train_val{id}_{epoch}.png')\n",
    "            plt.show()\n",
    "\n",
    "    #%% test\n",
    "    model = Resnet3D_m().cuda()\n",
    "    model.load_state_dict(torch.load(mod_loc+f'model_{id}.pt'))\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for batch_index, (inputs, gt_label) in enumerate(test_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation results\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Test accuracy: {}\".format(val_acc))\n",
    "\n",
    "    #%% plot train and val results\n",
    "    epochs_list = list(range(opt['epochs']))\n",
    "    plt.figure()\n",
    "    plt.plot(epochs_list, train_accs, '-o', label='training set accuracy')\n",
    "    plt.plot(epochs_list, val_accs, '--x', label='validation set accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('prediction accuracy')\n",
    "    plt.ylim(0.5, 1)\n",
    "    plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "    plt.legend()\n",
    "    plt.savefig(fig_loc+f'train_val{id}.png')\n",
    "    plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge the LCD 2d Resnet18\n",
    "\"\"\"\n",
    "\n",
    "#%%\n",
    "from modules import *\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "#%% prepare data\n",
    "neg, pos = torch.load('./data/LCD/neg_pos.pt') # check prep_data.py for more info\n",
    "neg_all, pos_all = neg.reshape(-1,1,64,64), pos.reshape(-1,1,64,64)\n",
    "if True:  # if False means split by objects\n",
    "    idx = torch.randperm(pos_all.shape[0])\n",
    "    neg_all = neg_all[idx]\n",
    "    pos_all = pos_all[idx]  #36992, 64, 64]\n",
    "num_train = 29600\n",
    "num_val = 3696\n",
    "num_test = 3696\n",
    "split1 = num_val+num_train\n",
    "split2 = num_val+num_train + num_test\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.cat((pos_all[:num_train], neg_all[:num_train]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_train, dtype=int), torch.zeros(num_train,  dtype=int)), dim=0))\n",
    "val_dataset = Data.TensorDataset(torch.cat((pos_all[num_train:split1],neg_all[num_train:split1]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_val, dtype=int), torch.zeros(num_val, dtype=int)), dim=0))\n",
    "test_dataset = Data.TensorDataset(torch.cat((pos_all[split1:split2], neg_all[split1:split2]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_test, dtype=int), torch.zeros(num_test, dtype=int)), dim=0))\n",
    "train_batchsize = 128\n",
    "eval_batchsize = 64\n",
    "train_loader = DataLoader(train_dataset, train_batchsize, shuffle=True)                                      \n",
    "validation_loader = DataLoader(val_dataset, eval_batchsize)\n",
    "test_loader = DataLoader(test_dataset, eval_batchsize)\n",
    "\n",
    "#%%\n",
    "id0, id1 = 'LCD2', 'LCD3'\n",
    "\n",
    "teacher0 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "teacher0.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False) # original\n",
    "teacher0.load_state_dict(torch.load(f'teachers/teacher{id0}.pt'))\n",
    "\n",
    "teacher1 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "teacher1.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False) # original\n",
    "teacher1.load_state_dict(torch.load(f'teachers/teacher{id1}.pt'))\n",
    "\n",
    "model = Judge(teacher0, teacher1).cuda()\n",
    "\n",
    "#%% train_net\n",
    "id = 'LCD_merge'\n",
    "best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "optimizer1 = torch.optim.RAdam(model.parameters(),\n",
    "                lr= 0.001,\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "scheduler1 = torch.optim.lr_scheduler.MultiStepLR(optimizer1, milestones=[50, 70], gamma=0.1)\n",
    "optimizer2 = torch.optim.SGD(model.gate_parameters(), lr=0.2, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.MultiStepLR(optimizer2, milestones=[], gamma=1)\n",
    "opt = {'epochs':100}\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lamb = 0.05\n",
    "for epoch in range(opt['epochs']):\n",
    "    model.train()\n",
    "\n",
    "    # print training info\n",
    "    print(\"### Epoch {}:\".format(epoch))\n",
    "    total_train_examples = 0\n",
    "    num_correct_train = 0\n",
    "\n",
    "    lamb += 0.05 * math.sqrt(lamb)\n",
    "    for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        gt_label = gt_label.cuda()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "        main_loss = loss_func(predictions, gt_label)\n",
    "        l0_loss = lamb * model.l0_loss()\n",
    "        loss = main_loss + l0_loss\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "        _, predicted_class = predictions.max(1)\n",
    "        total_train_examples += predicted_class.size(0)\n",
    "        num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "    # get results\n",
    "    train_acc = num_correct_train / total_train_examples\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # evaluation\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation resultsh\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # Finally, save model if the validation accuracy is the best so far\n",
    "    if val_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_acc\n",
    "        print(\"Validation accuracy improved; saving model.\")\n",
    "        torch.save(model.state_dict(), f'teachers/teacher{id}.pt')\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "\n",
    "#%% plot train and val results\n",
    "epochs_list = list(range(opt['epochs']))\n",
    "plt.figure()\n",
    "plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('prediction accuracy')\n",
    "plt.ylim(0.01, 1)\n",
    "plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "plt.legend()\n",
    "plt.savefig(f'train_val{id}.png')\n",
    "plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge the DBC 2d Resnet18\n",
    "\"\"\"\n",
    "#%%\n",
    "from modules import *\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "#%% prepare data\n",
    "neg_all = torch.load('./data/DBC/neg_all.pt') # check prep_data.py for more info\n",
    "pos_all = torch.load('./data/DBC/pos_all.pt')\n",
    "if True:  # if False means split by objects\n",
    "    idx = torch.randperm(pos_all.shape[0])\n",
    "    neg_all = neg_all[idx]\n",
    "    pos_all = pos_all[idx]\n",
    "num_train = 2600+2200\n",
    "num_val = 2200//2\n",
    "num_test = 2200//2\n",
    "split1 = num_val+num_train\n",
    "split2 = num_val+num_train + num_test\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.cat((pos_all[:num_train], neg_all[:num_train]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_train, dtype=int), torch.zeros(num_train,  dtype=int)), dim=0))\n",
    "val_dataset = Data.TensorDataset(torch.cat((pos_all[num_train:split1],neg_all[num_train:split1]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_val, dtype=int), torch.zeros(num_val, dtype=int)), dim=0))\n",
    "test_dataset = Data.TensorDataset(torch.cat((pos_all[split1:split2], neg_all[split1:split2]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_test, dtype=int), torch.zeros(num_test, dtype=int)), dim=0))\n",
    "train_batchsize = 64\n",
    "eval_batchsize = 32\n",
    "train_loader = DataLoader(train_dataset, train_batchsize, shuffle=True)                                      \n",
    "validation_loader = DataLoader(val_dataset, eval_batchsize)\n",
    "test_loader = DataLoader(test_dataset, eval_batchsize)\n",
    "\n",
    "#%%\n",
    "id0, id1 = 'DBC0', 'DBC1'\n",
    "teacher0 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True)\n",
    "teacher0.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "# teacher0.load_state_dict(torch.load(f'teachers/teacher{id0}.pt'))\n",
    "\n",
    "teacher1 = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=False)\n",
    "teacher1.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "teacher1.load_state_dict(torch.load(f'teachers/teacher{id1}.pt'))\n",
    "\n",
    "model = Judge(teacher0, teacher1).cuda()\n",
    "\n",
    "#%% train_net\n",
    "id = 'DBC_merge_goodnbad'\n",
    "best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "optimizer1 = torch.optim.RAdam(model.parameters(),\n",
    "                lr= 0.001,\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "scheduler1 = torch.optim.lr_scheduler.MultiStepLR(optimizer1, milestones=[50, 70], gamma=0.1)\n",
    "optimizer2 = torch.optim.SGD(model.gate_parameters(), lr=0.2, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.MultiStepLR(optimizer2, milestones=[], gamma=1)\n",
    "opt = {'epochs':100}\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lamb = 0.05\n",
    "for epoch in range(opt['epochs']):\n",
    "    model.train()\n",
    "\n",
    "    # print training info\n",
    "    print(\"### Epoch {}:\".format(epoch))\n",
    "    total_train_examples = 0\n",
    "    num_correct_train = 0\n",
    "\n",
    "    lamb += 0.05 * math.sqrt(lamb)\n",
    "    for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        gt_label = gt_label.cuda()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "        main_loss = loss_func(predictions, gt_label)\n",
    "        l0_loss = lamb * model.l0_loss()\n",
    "        loss = main_loss + l0_loss\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "        _, predicted_class = predictions.max(1)\n",
    "        total_train_examples += predicted_class.size(0)\n",
    "        num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "    # get results\n",
    "    train_acc = num_correct_train / total_train_examples\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # evaluation\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation results\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # Finally, save model if the validation accuracy is the best so far\n",
    "    if val_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_acc\n",
    "        print(\"Validation accuracy improved; saving model.\")\n",
    "        torch.save(model.state_dict(), f'teachers/teacher{id}.pt')\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "\n",
    "#%% plot train and val results\n",
    "epochs_list = list(range(opt['epochs']))\n",
    "plt.figure()\n",
    "plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('prediction accuracy')\n",
    "plt.ylim(0.01, 1)\n",
    "plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "plt.legend()\n",
    "plt.savefig(f'train_val{id}.png')\n",
    "plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Merge the LCD 3d Resnet18\n",
    "\"\"\"\n",
    "#%% load dependency\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from skimage.io import imread\n",
    "from datetime import datetime\n",
    "print('starting date time ', datetime.now())\n",
    "\n",
    "#%% prepare data\n",
    "neg, pos = torch.load('./data/LCD/neg_pos.pt') # neg and pos each has [1156,32,64,64]\n",
    "neg = torch.cat((neg[:,:8],neg[:,8:16],neg[:,16:24], neg[:,24:]), dim=0)\n",
    "pos = torch.cat((pos[:,:8],pos[:,8:16],pos[:,16:24], pos[:,24:]), dim=0) # shape [1156*4, 8, 64, 64]\n",
    "if True:  # if False means split by objects\n",
    "    idx = torch.randperm(pos.shape[0])\n",
    "    neg_all = neg[idx][:,None]\n",
    "    pos_all = pos[idx][:,None]\n",
    "num_train = 3600\n",
    "num_val = 512\n",
    "num_test = 512\n",
    "split1 = num_val+num_train\n",
    "split2 = num_val+num_train + num_test\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.cat((pos_all[:num_train], neg_all[:num_train]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_train, dtype=int), torch.zeros(num_train,  dtype=int)), dim=0))\n",
    "val_dataset = Data.TensorDataset(torch.cat((pos_all[num_train:split1],neg_all[num_train:split1]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_val, dtype=int), torch.zeros(num_val, dtype=int)), dim=0))\n",
    "test_dataset = Data.TensorDataset(torch.cat((pos_all[split1:split2], neg_all[split1:split2]), dim=0), \\\n",
    "                torch.cat((torch.ones(num_test, dtype=int), torch.zeros(num_test, dtype=int)), dim=0))\n",
    "train_batchsize = 128\n",
    "eval_batchsize = 64\n",
    "train_loader = DataLoader(train_dataset, train_batchsize, shuffle=True)                                      \n",
    "validation_loader = DataLoader(val_dataset, eval_batchsize)\n",
    "test_loader = DataLoader(test_dataset, eval_batchsize)\n",
    "\n",
    "#%%\n",
    "from modules import Resnet3D, Judge3D\n",
    "id0, id1 = 'DBC0', 'res3d1'\n",
    "client0 = Resnet3D()\n",
    "# client0.load_state_dict(torch.load(f'teachers/teacher{id0}.pt'))\n",
    "\n",
    "client1 = Resnet3D()\n",
    "client1.load_state_dict(torch.load(f'./data/results/models/{id1}/model_{id1}.pt'))\n",
    "\n",
    "model = Judge3D(client0, client1).cuda()\n",
    "\n",
    "#%% train_net\n",
    "id = 'res3d1_and_rand' # for diff. runs\n",
    "fig_loc = './data/results/merege/figures/'\n",
    "mod_loc = './data/results/merge/models/'\n",
    "if not(os.path.isdir(fig_loc + f'/{id}/')): \n",
    "    print('made a new folder')\n",
    "    os.makedirs(fig_loc + f'{id}/')\n",
    "    os.makedirs(mod_loc + f'{id}/')\n",
    "fig_loc = fig_loc + f'{id}/'\n",
    "mod_loc = mod_loc + f'{id}/'\n",
    "best_validation_accuracy = 0. # used to pick the best-performing model on the validation set\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "\n",
    "optimizer1 = torch.optim.RAdam(model.parameters(),\n",
    "                lr= 0.001,\n",
    "                betas=(0.9, 0.999), \n",
    "                eps=1e-8,\n",
    "                weight_decay=0)\n",
    "scheduler1 = torch.optim.lr_scheduler.MultiStepLR(optimizer1, milestones=[50, 70], gamma=0.1)\n",
    "optimizer2 = torch.optim.SGD(model.gate_parameters(), lr=0.2, momentum=0.9)\n",
    "scheduler2 = torch.optim.lr_scheduler.MultiStepLR(optimizer2, milestones=[], gamma=1)\n",
    "opt = {'epochs':100}\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "lamb = 0.05\n",
    "for epoch in range(opt['epochs']):\n",
    "    model.train()\n",
    "\n",
    "    # print training info\n",
    "    print(\"### Epoch {}:\".format(epoch))\n",
    "    total_train_examples = 0\n",
    "    num_correct_train = 0\n",
    "\n",
    "    lamb += 0.05 * (lamb**0.5)\n",
    "    for batch_index, (inputs, gt_label) in enumerate(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        gt_label = gt_label.cuda()\n",
    "        optimizer1.zero_grad()\n",
    "        optimizer2.zero_grad()\n",
    "\n",
    "        predictions = model(inputs)\n",
    "        main_loss = loss_func(predictions, gt_label)\n",
    "        l0_loss = lamb * model.l0_loss()\n",
    "        loss = main_loss + l0_loss\n",
    "        loss.backward()\n",
    "        optimizer1.step()\n",
    "        optimizer2.step()\n",
    "\n",
    "        _, predicted_class = predictions.max(1)\n",
    "        total_train_examples += predicted_class.size(0)\n",
    "        num_correct_train += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "    # get results\n",
    "    train_acc = num_correct_train / total_train_examples\n",
    "    print(\"Training accuracy: {}\".format(train_acc))\n",
    "    train_accs.append(train_acc)\n",
    "\n",
    "    # evaluation\n",
    "    total_val_examples = 0\n",
    "    num_correct_val = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad(): \n",
    "        for batch_index, (inputs, gt_label) in enumerate(validation_loader):\n",
    "            inputs = inputs.cuda()\n",
    "            gt_label = gt_label.cuda()\n",
    "            predictions = model(inputs)\n",
    "\n",
    "            _, predicted_class = predictions.max(1)\n",
    "            total_val_examples += predicted_class.size(0)\n",
    "            num_correct_val += predicted_class.eq(gt_label).sum().item()\n",
    "\n",
    "        # get validation results\n",
    "        val_acc = num_correct_val / total_val_examples\n",
    "        print(\"Validation accuracy: {}\".format(val_acc))\n",
    "        val_accs.append(val_acc)\n",
    "\n",
    "    # Finally, save model if the validation accuracy is the best so far\n",
    "    if val_acc > best_validation_accuracy:\n",
    "        best_validation_accuracy = val_acc\n",
    "        print(\"Validation accuracy improved; saving model.\")\n",
    "        torch.save(model.state_dict(), f'teachers/teacher{id}.pt')\n",
    "\n",
    "        epochs_list = list(range(epoch+1))\n",
    "        plt.figure()\n",
    "        plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "        plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.ylabel('prediction accuracy')\n",
    "        plt.ylim(0.5, 1)\n",
    "        plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "        plt.legend()\n",
    "        plt.savefig(fig_loc+f'train_val{id}_{epoch}.png')\n",
    "        plt.show()\n",
    "\n",
    "    scheduler1.step()\n",
    "    scheduler2.step()\n",
    "\n",
    "#%% plot train and val results\n",
    "epochs_list = list(range(opt['epochs']))\n",
    "plt.figure()\n",
    "plt.plot(epochs_list, train_accs, 'b-', label='training set accuracy')\n",
    "plt.plot(epochs_list, val_accs, 'r-', label='validation set accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('prediction accuracy')\n",
    "plt.ylim(0.01, 1)\n",
    "plt.title('Classifier training evolution:\\nprediction accuracy over time')\n",
    "plt.legend()\n",
    "plt.savefig(f'train_val{id}.png')\n",
    "plt.show()\n",
    "\n",
    "print('done')\n",
    "print('End date time ', datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c728c5ad72b5fd3c6e083c4badca00ca04470578383c0e9d983163c40aa43e1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
